[[lab1]]
= Lab 1: {lab1-title}

For me, the best way to start learning a new technology is by running all the stuff related to them inside a {docker} container.
By this way, I can abstract myself about the related installation procedures and go directly to the point.

So, I started my labs by following the steps on the {quick-start-page}.
These steps use Docker and {DockerCompose}.

== Prerequisites

. {Docker} installed.
. {DockerCompose} installed.

== Step 1 - Download docker-compose.yml

My first steps were create a working directory and download the `docker-compose.yml` file:

----
$ mkdir -p ~/labs/spring-cloud-dataflow && cd $_

$ wget -c https://raw.githubusercontent.com/spring-cloud/spring-cloud-dataflow/v1.4.0.RELEASE/spring-cloud-dataflow-server-local/docker-compose.yml
----

By default, this file is configured to use {Kafka} and {Zookeeper}:

----
$ cat docker-compose.yml
version: '3'

services:
  kafka:
    image: wurstmeister/kafka:0.10.1.0
    expose:
      - "9092"
    environment:
      - KAFKA_ADVERTISED_PORT=9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
    depends_on:
      - zookeeper
  zookeeper:
    image: wurstmeister/zookeeper
    expose:
      - "2181"
    environment:
      - KAFKA_ADVERTISED_HOST_NAME=zookeeper
  dataflow-server:
    image: springcloud/spring-cloud-dataflow-server-local:1.4.0.RELEASE
    container_name: dataflow-server
    ports:
      - "9393:9393"
    environment:
      - spring.cloud.dataflow.applicationProperties.stream.spring.cloud.stream.kafka.binder.brokers=kafka:9092
      - spring.cloud.dataflow.applicationProperties.stream.spring.cloud.stream.kafka.binder.zkNodes=zookeeper:2181
    depends_on:
      - kafka
  app-import:
    image: alpine:3.7
    depends_on:
      - dataflow-server
    command: >
      /bin/sh -c "
        while ! nc -z dataflow-server 9393;
        do
          sleep 1;
        done;
        wget -qO- 'http://dataflow-server:9393/apps' --post-data='uri=http://bit.ly/Celsius-SR1-stream-applications-kafka-10-maven&force=true';
        echo 'Stream apps imported'
        wget -qO- 'http://dataflow-server:9393/apps'  --post-data='uri=http://bit.ly/Clark-GA-task-applications-maven&force=true';
        echo 'Task apps imported'"
----

I could also change these settings to use {RabbitMQ}, {MySQL}, and {Redis}.
I show you how to do this in the <<lab1-step9,step 9>> of this lab.

[[lab1-step2]]
== Step 2 - Start Docker Compose

I started `docker-compose`:

----
docker-compose up
----

The above command downloaded all the necessary Docker images (configured in `docker-compose.yml` file).
After that, it also created and started the containers.

NOTE: The current shell remains blocked until we stop `docker-compose`.

== Step 3 - Launch the Spring Cloud Data Flow Dashboard

I opened the dashboard at http://localhost:9393/dashboard.

== Step 4 - Create a Stream

I did some steps in the UI of the dashboard.

I used `Create Stream` under `Streams` tab to define and deploy a stream `time | log` called `ticktock`.
This was done in two steps:

image::01.png[title="Step 4.1"]

image::02.png[title="Step 4.2"]

After that, the `ticktock` stream was deployed:

image::03.png[title="Step 4.3"]

Two running stream apps appears under `Runtime` tab:

image::04.png[title="Step 4.4"]

Then I clicked on `ticktock.log` to determine the location of the stdout log file.

image::05.png[title="Step 4.5"]

== Step 5 - Verify that events are being written to the ticktock log every second

----
$ log=/tmp/spring-cloud-deployer-5011048283762989937/ticktock-1524755341440/ticktock.log/stdout_0.log
$ tail -f $log
----

This last step did not work icon:bomb[].
Obvious (I thinked) ... the above file is inside the container!
So I started to investigate how to read this file by using Docker reading the {reference-guide} and yes, in that, I found the solution to type the correct command:

----
$ docker exec -it dataflow-server tail -f $log
----

[[lab1-negative-1]]
My conclusion was: the {quick-start-page} needs to be fixed (on this step) to present the above command correctly.

== Step 6 - Delete a Stream

image::06.png[title="Step 6.1"]

image::07.png[title="Step 6.2"]

== Step 7 - Destroy the Quick Start environment

I opened another shell and typed:

----
docker-compose down
----

== Step 8 -  Remove all finished containers

To remove all finished containers, I did:

----
docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs sudo docker rm
----

[[lab1-step9]]
== Step 9 - Change docker-compose.yml to use RabbitMQ, MySQL and Redis and test it

In order to change the contents of `docker-compose.yml` I cloned the repository of this tutorial:

[subs="attributes"]
----
$ git clone {uri-source-code} tutorial
----

After download this repository, I applied a patch on `docker-compose.yml`:

----
$ patch docker-compose.yml < tutorial/files/docker-compose.yml.patch
----

This is the contents of the file `docker-compose.yml.patch`:

[source,diff]
----
include::{projectdir}/files/docker-compose.yml.patch[]
----

Now I could repeat the steps from this tutorial beggining from <<lab1-step2,step 2>>.

More details about the configuration that I made in `docker-compose.yml` throught the use of of my patch can be found in {uri-reference-guide}#getting-started-customizing-spring-cloud-dataflow-docker["Docker Compose Customization"] on {reference-guide}.

[[lab1-conclusions]]
== Conclusions

Positive points: ::
* The Docker configuration to run SCDF is well done and absolutely finished.
I did not have to do anything to quickly get things running.
* Running SCDF on Docker on my machine was extremely fast.
* Using Docker Compose, the switching from Kafka to RabbitMQ was quite simple (after I resolve a problem with a non documented step).
* The UI interface (provided by the dashboard) is pretty simple.
All sources, sinks, and processors are elements that could be configured through the UI.
The stream creation using the UI is very basic (for me this is nice) but can also be configured.
** Even though I have not done configurations on elements of UI, a good video that shows how to do this is {yG}.
Negative points: ::
* The {quick-start-page} that I used to follow steps has a bug <<lab1-negative-1,like I said>>.
* Even the {reference-guide} has some missed points that I had to discover myself.

== References

* {quick-start-page}
* {reference-guide}
